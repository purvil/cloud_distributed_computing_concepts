{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leader Election\n",
    "* Bank account details are replicated at a few servers, but one of these servers are responsible for all reads and writes, that is leader among replicas.\n",
    "    * What is leader crash?\n",
    "    * what if there are more than 1 leader?\n",
    "    * WHat if servers disagree for leader?\n",
    "* In the sequencer based algorithm for total ordering  of multicast, the sequencer is a leader\n",
    "* Group of NTP servers, who is root servers.\n",
    "* Apache zookeeper, google's chubby\n",
    "* From group of process we have to choose leader and let everyone know.\n",
    "* N process, each process has unique id like ip address and port number, Failure may occur during election.\n",
    "\n",
    "### Calling for election\n",
    "* ANy process can cal for an election\n",
    "* A process can call for at most one election at a time\n",
    "* Multiple process can call for election. All of them together yield single leader.\n",
    "* Result of election should not depend on which process calls for it.\n",
    "* At the end of election protocol the non faulty process with the best election attribute value is elected. Common attribute, leader with highest id. or fasted cpu or most disk space, or most number of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring leader election\n",
    "* Nprocess are in logical ring, ith process has communication channel to (i+1) % N.\n",
    "* All message are sent clockwise around the ring.\n",
    "![](images/ring.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Any process Pi, which discovers the old coordinator has failed initiate an Election message with its own id:attr.\n",
    "* When other process receive this message, it compares it value with own attributes.\n",
    "* If attribute is greater, then forward the message\n",
    "* If smaller then overwrite with own id:attr and forwards it.\n",
    "* After making one circle message again come to same process ,then that process send Elected message to neighbor with its id.\n",
    "* ALl process mark their elected variable = elected process id\n",
    "* 3N - 1 message in worst case. Best case then 2N messages.\n",
    "* Multiple initiator\n",
    "    - Each process cache initiator of election.\n",
    "    - Each process suppresses election message of any lower id initiators.\n",
    "    - Update cache if receive higher id initiator's message\n",
    "* Effect of failure:\n",
    "    - Elected node failed then, predecessor detect failure then start new election.\n",
    "\n",
    "###  Google'e Chubby\n",
    "* System for locking\n",
    "* Group of replicas, need to have a master server elected at all time.\n",
    "* Potential leader tries to get votes from other servers\n",
    "* Each server votes for at most one leader\n",
    "* Server with majority of votes become new leader and inform everyone.\n",
    "* After election finishes other servers promise not to run election again for a while. While = master lease time = few seconds\n",
    "* Master lease can be renewed by the master as long as it continues to win a majority each time.\n",
    "* If master fails, automatic re election will conducted.\n",
    "\n",
    "### Zookeeper\n",
    "* Each server creates new sequence number (ids). Elect the highest id server as leader.\n",
    "* Everyone monitors current master, on failure re election, it can lead to flood of election messages\n",
    "* Each process monitors its next higher id process.\n",
    "* If that successor was the leader and it has failed, become the new leader.\n",
    "* What if id conflicts?\n",
    "    - 2 phase commit, Leader sends NEW_lEADER message to all. Each process responds with ACK to at most 1 leader that is one with highest process id. Leader waits for a majority of ACKS and then sends commit to all. On commit everyone update leader variable.\n",
    "    \n",
    "### Bully algorithm\n",
    "* All process know other process id.\n",
    "* When a process finds the coordinator has failed via failure detector,\n",
    "    - If it knows it is highest id, it elects it self as coordinator and send message to everyone with lower id, that election is completed. \n",
    "    - Else initiates an election by sending Election message\n",
    "        - Election message is sent to process with higher id.\n",
    "        - If receives no answer within timeout, calls itself leader and sends message to all lower id process that election completed I am leader\n",
    "        - If answer receive from high id process, wait for coordinator message, if not receive within timeout start new election."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Exclusion\n",
    "* Bank's server in cloud: simultaneously 2 customer put money in my account. Initially balance was 1000. BOth customer trying to add 10000. Both read initial value concurrently from bank's server. Both add 10000 to this amount and write final amount to server.\n",
    "* To resolve it we can provide mutual exclusive access to account, allow only 1 client to access account.\n",
    "* In Distributed system locking  files is needed \n",
    "* Accessing objects in safe and consistent way\n",
    "* Chubby is google's locking system\n",
    "* Apache zookeeper is used to coordinate among server.\n",
    "* Critical section problem\n",
    "    - Piece of code for which we need to ensure there is at most one process is executing it at any given point of time.\n",
    "    - enter() to enter in critical section\n",
    "    - AccessResource() to run critical section code\n",
    "    - exit() to exit critical section.\n",
    "* For single OS structure,\n",
    "    - We can use Semaphores, mutexes, condition variables, monitors.\n",
    "    - Semaphore is an integer that can be accessed via 2 special function\n",
    "    - Semaphore S = 1// mac allowed process\n",
    "    - wait(S) before entering the section and signal(S) to exit the section.\n",
    "* In distributed system shared variable approach is not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed system Central algorithm\n",
    "* Elect central master/leader using election algorithm\n",
    "* Master keeps queue of waiting process, who wish to access the CS.\n",
    "* A special token which allows its holder to access CS.\n",
    "* Action of any process in a group\n",
    "    - enter(): send request to master, wait for token from master\n",
    "    - exit() : Send back token to master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2 message for each enter, 1 message for each exit\n",
    "* Master is single point of failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring based mutual exclusion\n",
    "![](images/ring_mutual.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* N process organized in virtual ring.\n",
    "* Each process can send  message to its successor in ring\n",
    "* Exactly 1 token\n",
    "* enter(): wait until you get token\n",
    "* exit(): pass token to successor\n",
    "* If receive token and currently not in enter(), pass to successor.\n",
    "* Per request message might be as high as N\n",
    "* 1 message per exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ricart-Agrawala'a problem\n",
    "*  When process Pi want to enter CS it call enter(), it multicast message to all process, request <T,Pi> where T = current Lamport timestamp at Pi\n",
    "* Wait until all other process have responded positively to request. it change state to Held.\n",
    "* Request are granted in order of causality\n",
    "* Pi in request <T, Pi> is used to break ties, as lamport timestamp are not unique for concurrent events.\n",
    "* Suppose process Pi receive request of <Tj, Pj>\n",
    "    - if Pi's state is Held or wanted and (Ti, i) < (Tj, j) add request to local queue\n",
    "    - else reply to Pj\n",
    "* exit() at Pi\n",
    "    - change state to released and send reply to all queued process\n",
    "\n",
    "### Maekawa's algorithms\n",
    "* Above algo require response from all the process in a group.\n",
    "* Instead we can get reply from some of the process.\n",
    "* Each process Pi asscoated with voting set Vi\n",
    "* Each process belongs to its own voting set.\n",
    "* Intersection of any 2 voting state must not be empty\n",
    "* Each voting set has size K. Each process belongs to M other voting set, K = M = $\\sqrt{N}$ works best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* one way of doing it is put N process in $\\sqrt{N}$ by $\\sqrt{N}$ matrix and for each Pi, its voting set Vi = row containing Pi + column containing Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Maekawa.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each process request permission from only its voting set members.\n",
    "* Each process gives permission to at most 1 process at a time.\n",
    "* state = released, voted = false\n",
    "* enter() at process Pi\n",
    "    - state = wanted\n",
    "    - Multicast request message to all processes in Vi\n",
    "    - wait for Reply message from all Vi processes\n",
    "    - state = held\n",
    "* exit()\n",
    "    - state = released\n",
    "    - Multicast Release to all process in Vi.\n",
    "* If Pi receive request fro Pj\n",
    "    - if (state == Held or voted =true)\n",
    "        - queue request\n",
    "    - send Reply to Pj and set voted = true\n",
    "    - When Pi receives a release from Pj\n",
    "    - if (queue empty)\n",
    "        - voted = false\n",
    "    - else\n",
    "        - dequeue head of queue, say Pk\n",
    "        - send reply to Pk\n",
    "        - voted = true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* only 1 group's one process will win,\n",
    "    - suppose Pi in 2 group it can send yes to only one of the process of specific group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2$\\sqrt{N}$ messages per enter, $\\sqrt{N}$ messages per exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPC\n",
    "* Remote procedure call\n",
    "* Allow to call other process' function.\n",
    "* Other variant in object based model is RMI (Remote Method Invocation)\n",
    "* Local procedure call LPC\n",
    "    - Call from 1 function to other function in the same process\n",
    "    - Use stack to pass arguments and return values\n",
    "    - Access object via pointer or reference\n",
    "    - LPC has exactly once semantics. Function gets called EXACTLy once.\n",
    "* In RPC we can not use pointer, we use global reference like IP + Port + object number.\n",
    "* RPC can also be in same host, like between two different process in same computer\n",
    "* Problem is \n",
    "    - Request message might be dropped\n",
    "    - Reply message is dropped\n",
    "    - Called process fails before or after execution of called function.\n",
    "    - Request message is duplicated.\n",
    "![](images/RPC.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Idempotent operation can tolerate at least 1, semantics .For example x = 1\n",
    "* Non idempotent like x+=1 .\n",
    "![](images/stub.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Client stub: same function signature as callee(). Allows same caller() code for LPC and RPC\n",
    "* Communication module, forwards requests and replies to appropriate hosts server\n",
    "* Dispatcher: Selects which server stub to forward request to.\n",
    "* Server stub: Calls callee(), allows it to return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Programmer write code only for caller and callee. Code for remaining components generates automatically from function signature.\n",
    "* Ex. CORBA, Sun RPC, JAVA RMI.\n",
    "\n",
    "#### Marshalling\n",
    "* Different architecture use different ways of representing data,\n",
    "    - Big endian(IBM, system 360), Little endian (Intel)\n",
    "* Caller and callee process uses its own platform dependent way of storing data, middleware has a common data representation (CDR), platform independent.\n",
    "* Caller process converts argument to CDR, (Marshalling)\n",
    "* Callee process extracts argument from message into own platform dependent form (Unmarshalling)\n",
    "* Return values are again marshalled and unmarshalled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction\n",
    "* Series of operations executed by client\n",
    "* Each operation is RPC to server\n",
    "* Transaction either complete and commit at server or aborts and no effect on server.\n",
    "![](images/rpc_transaction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Atomicity : all or nothing, a transaction should complete successfully, so its effects are recorded in the server objects or it has no effects at all.\n",
    "* Isolation: Need transaction to be indivisible (atomic) from other transaction's point of view\n",
    "    - No access to intermediate result or state of other transaction\n",
    "    - Free from interference from other transaction.\n",
    "* ACID property of transaction\n",
    "    - Atomicity: All or nothing\n",
    "    - Consistency: If the server starts in the consistent state, the transaction end server in consistent state\n",
    "    - Isolation: Transaction must be performed without interference from other transaction. Non final effects of transaction must not be visible to other transaction.\n",
    "    - Durability: After transaction completed successfully, all its effects are saved in permanent storage.\n",
    "* When we do not care about ACID\n",
    "![](images/loss_update.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Untitled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To prevent it we can execute transaction one at a time, but we care about number of transaction per seconds for performance and revenue.\n",
    "\n",
    "### Serial Equivalence\n",
    "* We have multiple transaction and interleave operation of all transaction in such a way that it output like they have executed serially.\n",
    "* 2 operations are said to be conflicting operations. if their combined effect depends on the order they are executed.\n",
    "    * read(x) and write(x)\n",
    "    * write(x) and read(x)\n",
    "    * write(x) and write(x)\n",
    "* 2 transaction are serially equivalent only if and only if all pairs of conflicting operations are executed in same order. \n",
    "* For T1 and T2 task, in each step either T1's transaction should execute first than T2's or other way around. But for all operations it should be the same.\n",
    "* If all pair executed in same way, then transaction is serially equivalent.\n",
    "![](images/serial1.PNG)\n",
    "![](images/serial2.PNG)\n",
    "\n",
    "* At the end of transaction T, check for serial equivalence with all other transaction, If not serially equivalent abort T.\n",
    "\n",
    "### Pessimist Concurrency\n",
    "* Assume the worst prevent transaction from accessing same object. Ex. Locking\n",
    "* Exclusive Lock:\n",
    "    - Each object has a lock. At most one transaction can enter inside lock. When done T release the lock. Like mutual exclusion.\n",
    "* But we need more transaction per second. Exclusive locking reduce concurrency. It is ok to allow transaction to read concurrently.\n",
    "* Read Write lock:\n",
    "    - In read mode multiple transaction allowed in\n",
    "    - In write mode exclusive mode.\n",
    "* 2 Phase locking\n",
    "    - A transaction can  not acquire or promote lock after it has started releasing lock\n",
    "* Downside of locking is deadlock\n",
    "    - We can have lock timeout, if lock can not acquire within a time bound release what you have.\n",
    "    - Deadlock detection: Keep track of wait-for graph, find cycle in it, if found abort transaction.\n",
    "### Optimistic Concurrency:\n",
    "* Assume the best, allow transaction to write, but check later. Check at commit time.\n",
    "* Allow write and read at will, at commit time check for serial equivalence. if not full filled, abort.\n",
    "* Timestamp ordering\n",
    "    - Assign each transaction an id. It determines position in serialization order.\n",
    "    - Ensure that for transaction T both are true,\n",
    "        - T's write to object O allowed only if transactions that have read or written O had lower ids than T.\n",
    "        - T's read to object O is allowed only if O was last written by transaction with lower id than T\n",
    "    - Implemented by maintaining read and write timestamps for object.\n",
    "* Multiverstion concurrency system\n",
    "    - For each object, per transaction version of the object is maintained and committed version is maintained.\n",
    "    - Each tentative version has timestamp. Some system maintain both read and write timestamp. On read and write find correct tentative version to read and write from. \n",
    "  \n",
    "  \n",
    "### Eventual consistency:\n",
    "* Only one pair of each data item. Last write wins (Timestamp based on physical time)\n",
    "* Another approach to use vector clock, for causal ordering. Checks, New write is strictly newer than current value or new write conflicts with existing value. In this case we have sibling value. for that key we maintain 2 values, which will resolve by user or application automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication\n",
    "* In concurrency we have multiple client, connected with one server.\n",
    "* Replication focus on server side, when object is stored at multiple servers, with or without replication.Replication is needed for fault tolerance and load balancing. Leads to higher availability.\n",
    "* We have to provide,\n",
    "    - Replication transparency, client should not be aware of multiple copy of data\n",
    "    ![](images/transparency.PNG)\n",
    "    - Replication Consistency, All client see single consistent copy of data, in spite of replication\n",
    "- Passive replication: Use primary replica (master), master will pass data to slave nodes. On master failure, run leader election.\n",
    "- Active replication: Treats all replica identically, multicast to all replica.\n",
    "\n",
    "* Both approach use replicated state machines. Multiple copy of state machine begin at start state and receiving same inputs in the same order will arrive at the same state having generated the same outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One copy serializability\n",
    "* A concurrent execution of transaction in a replicated database is one copy serializable if it is equivalent to a serial execution of these transaction over single logical copy of the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Phase commit\n",
    "* Transaction T may touch objects reside on different servers. We have to ensure that all the server commit update from  T => T will commit. Or non of the commit => abort T\n",
    "* We have coordinated server. Send prepare message to server. Save update to disk and reply with yes or no.  If any NO received, or timeout, send abort to all. If all yes send commit, when server receive commit it will commit updated from disk to store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Graph Processing\n",
    "* Graph is network\n",
    "* A graph has vertices and edges that connect pairs of vertices.\n",
    "* Find shortest paths between pairs of vertices\n",
    "* To store entire graph on one server is not possible.\n",
    "* We can not use Hadoop as for each iteration of BFS we need new map and reduce phase. Very slow\n",
    "\n",
    "### Bulk synchronous parallel model\n",
    "* We have local computation parallel across the nodes. Think like each node process one vertex. All processor meet barrier where all waits to complete the other process and proceed to next iteration.\n",
    "![](images/bulk.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assign each vertex to server, each server gets subset of vertices.\n",
    "* In each iteration server performs Gather-Apply-Scatter \n",
    "    - Gather meaning get all neighboring vertices\n",
    "    - Apply: Compute own new value from own old value and gathered neighbors\n",
    "    - Scatter: send out new value to neighboring vertices.\n",
    "* Hash based assignment of vertices to server\n",
    "* Locality based: Assign vertices with more neighbor to the same server as its neighbors. \n",
    "*\n",
    "### Pregal\n",
    "\n",
    "* There is a master maintain list of worker servers. Monitors workers and restart on failure, provide UI monitoring tool\n",
    "* Worker processes its vertices, communicate with other workers.\n",
    "* Persistent data is stored as files on distributed storage system like GFS or BigTable. Temporary data is stored in local disk.\n",
    "* Master assign vertices to each worker, Each worker load vertices and mark it active.\n",
    "* Master instructs each worker to perform iteration.\n",
    "    * Each worker loops through active vertices and computes for each vertex.\n",
    "    * Messages can be sent whenever but need to be delivered before end of iteration (Barrier)\n",
    "    * When all workers reach iteration barrier, master start next iteration\n",
    "* Computation ends when in some iteration, no vertices are active and when no messages are in transit.\n",
    "* Master instruct each worker to save its portion of the grapn.\n",
    "* Checkpoint is imposed by master on workers to save state of their on persistent storage.\n",
    "* Failure detection using ping message from master to worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small World networks\n",
    "* Path length: Shortest length between 2 vertex.\n",
    "* Clustering coefficient:(CC) P(A-B are connected | A-C edge and C-B edge) Complete graph has CC = 1, tree graph has CC = 0\n",
    "* Ring path has high CC, long paths\n",
    "* Random graph, low CC, short paths\n",
    "* Small world network: high CC, short paths\n",
    "![](images/small_world_graph.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most natural evolved networks are small world.\n",
    "#### Degrees\n",
    "* Number of immediate neighbors of vertex is called Degree.\n",
    "* Degree distribution: What is the probability of a given node having k edges(neighbors, friends)\n",
    "* Regular graph: All node same degree\n",
    "* Gaussian\n",
    "* Random \n",
    "![](images/power_law.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Killing large number of randomly chosen nodes does not disconnect graph.\n",
    "* Killing a few high degree nodes will disconnect graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Routing via highe degree certex is  not always good regardless of shortest path as it may be heavily overloaded. So we need some randomness in path selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling\n",
    "* We have limited processor, memory, disk and network.\n",
    "* We need\n",
    "    * Good throughput or response time for task.\n",
    "    * High utilization of resources.\n",
    "* For single processor system\n",
    "    - FIFO, batch application\n",
    "    - Shortest task first, batch application\n",
    "    - Priority scheduling\n",
    "    - Round robin: Task is run for small time then next task for small time. Interactive application, When user need quick response from system use it\n",
    "\n",
    "### Hadoop Scheduling\n",
    "* Hadoop job has map and reduce task\n",
    "* Hadoop YARN has\n",
    "    - Hadoop Capacity Scheduler: \n",
    "        - Contains multiple queue, Each queue has multiple jobs, Each queue guaranteed some portion of cluster capacity\n",
    "        - Queue 1 is given 80% of cluster, Queue 2 is given 20% of cluster. Higher priority jobs go to queue 1.\n",
    "        - For jobs within same queue, FIFO typically used. \n",
    "        - Admin can configure each queue with limit. Soft limit: How much % of cluster is the queue guaranteed to occupy, Hard limit: max % of cluster the queue is guaranteed, Queue can not cross hard limit\n",
    "        - Elasticity: A queue allowed to occupy more of cluster if resources free. But if other queues below their capacity limit now get full need to give these other queue resources\n",
    "        - Can not stop a task half way through. When reducing % cluster to a queue wait until some tasks of that queue have finished.\n",
    "        - Queue can have sub queue and sub queues can share resources equally.\n",
    "    - Hadoop Fair Scheduler\n",
    "        - All jobs get equal share of resources.\n",
    "        - If only 1 job 100% of cluster, Another job arrives, job given equal % of cluster.\n",
    "        - Divide cluster in pool, one pool per user\n",
    "        - Resources divided equally among pools\n",
    "        - Within each pool, can use either fair share scheduler or FIFO or configurable\n",
    "        - Some pools may have min shares\n",
    "            - Min % of cluster that pool is guaranteed\n",
    "        - When min share not met in a pool for a while, take resources away from other pools, pre-empting jobs in those pools, Too kill most recently started task is killed\n",
    "* Estimate time taken by Hadoop job\n",
    "    - Calculate running time of task as proportional to size of input.\n",
    "    - Average of other task time in given job  weighted by input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dominant Resource Fairness (DRF)\n",
    "* Provide fairness across job with multi resource requirements\n",
    "* Useful to schedule VM and Hadoop in a cluster.\n",
    "* Used in Mesos\n",
    "* Job 1 task : 2 CPU, 8 GB\n",
    "* job 2 task : 6 CPU, 2 GB\n",
    "* Cloud has 18 CU and 32 GB RAM\n",
    "* Each job 1 task consume % of total CPU 2/18 = 1/9\n",
    "* Each job 1 task consume % of total RAM 8/36 = 2/9\n",
    "* Job 1's dominant resource is RAM. <e,pry intensive.\n",
    "* Job 2 is CPU incentive.\n",
    "* For given job the % of its dominant resource type that it gets cluster wide, is the same for all jobs.\n",
    "    - Job 1's % of RAM = Job 2's % of CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File System\n",
    "* Contains file and directories\n",
    "* Higher level of abstraction: Prevents users and processes from dealing with disk blocks and memory blocks.\n",
    "* Typical file has header and lots of blocks. Size of blocks are in MBs\n",
    "* Header has Time stamp (creation,read, write), File type, Ownership, access control list, reference count(How many directories containing this file)\n",
    "* Directory are just file, with their data containing pointers to files\n",
    "* We have a file discriptors which is used to access a file. Each process has to open the file before reading writing file. File discriptor maintains internal read write pointer pointing to an offset within a file. read() reads number of bytes starting from that pointer and automatically advances pointer. lseek() moves read write pointer to position offset within file.\n",
    "* link(): creates a new link to file. increment reference count to file  (hard link)\n",
    "* Symbolic link creates another file pointing to this file, does not change reference count\n",
    "* unlink() : decrement reference count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed file system\n",
    "* Files are stored in server machine. Cline machine does RPC to perform operations on file.\n",
    "* We need\n",
    "    - Transparency : Client access DFS files as if it were accessing local files. Same API as local files, client do not see change, need to make location, replication invisible to client\n",
    "    - Support concurrent clients: Multiple client processes read write concurrently\n",
    "    - Replication : for fault tolerance.\n",
    "* At most once operation vs At least once operation\n",
    "    - Append operation can not be repeated so it should be at most once\n",
    "    - Idempotent operation have no side effects when repeated, like they can use at least once semantics Ex. Read at absolute position in file.\n",
    "\n",
    "### Security:\n",
    "* Authentication : Verify that a given user is who they claim to be\n",
    "* Authorization : After user authenticate, verify that the file they are trying to access\n",
    "    - Access control list = per file, list of allowed users and access type for each user\n",
    "    - Capability Lists : per user, list of files allowed to access and type of access allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DFS\n",
    "* DFS run on server and there are multiple clients\n",
    "    - Flat file service runs on server\n",
    "    - Directory service at server, talks to flat file service\n",
    "    - Client service: At client, talks to Directory service and flat file service.\n",
    "* We read file using file_id, position, num_bytes to read. File id is unique id of file, it is not a file descriptor. THere are no file descriptor as server has to be stateless so it is easier to recover after failure.\n",
    "* Write similar to read\n",
    "* create/delete via file_id\n",
    "* get_attributes/set_attributes (file_id, buffer)\n",
    "* Directory services provides\n",
    "    - lookup (dir, file_name) : return file_id\n",
    "    - add_name (dir_file_name) : increment ref count\n",
    "    - un_name (dir, file_name) : decrements ref count\n",
    "    - get_names(dir, pattern) : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFS (Network File System)\n",
    "![](images/nfs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NFS Client system\n",
    "    - Integrated with OS\n",
    "    - Perform RPS to NFS server system for DFS operation\n",
    "* NFS Server system\n",
    "    - Plays role of both flat file service and directory service\n",
    "    - Allows mounting of file and directories.\n",
    "    - Mount does not copy the file, just point to that directory now.\n",
    "* Virtual File system\n",
    "    - Allows process to access file via file descriptor\n",
    "    - So local and remote file are indistinguishable which provide transparency.\n",
    "    - Names all files uniquely\n",
    "    - Keeps data structure for each mounted file system\n",
    "    - Keeps v-node for each open file, if local file v-node points to local disk i-node. If remote v-node has address of NFS server.\n",
    "* Sever optimization\n",
    "    - Sever caching : Store in memory, recently accessed blocks\n",
    "* Writes:\n",
    "    - Delayed Write : write in memory, flush to disk every 30s, fast but not consistent\n",
    "    - Write through : Write to disk immediately before acking client.\n",
    "* Client caching:\n",
    "    - Client cache recently accessed block\n",
    "    - Each block in cache is tagged with,\n",
    "        - Time when the cache entry was last validated\n",
    "        - Time when block last modified on server\n",
    "        - We have freshness interval to compromise between consistency and efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFS (Andrew File System)\n",
    "* Whole file serving and whole file caching\n",
    "* Most file access are by single user, most files are small.\n",
    "* Read and write are optimistic\n",
    "    - Done on local copy of file at client\n",
    "    - When file closed write propogated to server\n",
    "* When client open file, server send entire file. If another client modify and close same file, server will callback all client which has that file to mark as valid or canceled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed shared memory\n",
    "* Process could share memory page shared. Which is called distributed shared memory.\n",
    "* Cache is maintained at each process. It stores pages accessed recently by that process\n",
    "* Read write first go to cache. WHen page is cache then page hit, otherwise page fault.\n",
    "* When page fault occurs, kernel trap handler invokes DSM software or may contact other process in DSM group via multicast.\n",
    "* Owner process has latest version of page. \n",
    "* Each page can be in read or write state. When page in R state, owner has an R copy, but other processes may also have R copies. WHen page is in W state only owner has a copy\n",
    "* When page is in W mode and other process wants to read it, it can multicast message to request degrade W copy to R.\n",
    "* If all copy are in R, then process which want to write will request all other copy to invalidate their copy via multicast. And write to own copy.\n",
    "* Update approach\n",
    "    - Multiple processes allowed to have page in W state. On write to page, multicast newely written value to all other holder of that page.\n",
    "    - Other process can then continue R and W.\n",
    "\n",
    "* Consistency of DSM can be implemented as\n",
    "    - Linearizability\n",
    "    - Sequential consistency\n",
    "    - Causal consistency\n",
    "    - FIFO consistency\n",
    "    - Eventual Consistency\n",
    "* GOing top to down in above consistency, will increase speed but consistency will be weaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security\n",
    "\n",
    "### Leakage \n",
    "* Unauthorized access to service or data, Ex. Someone knows your bank balance\n",
    "\n",
    "### Tampering\n",
    "* Unauthorized modification of service or data\n",
    "* Someone modify bank balance\n",
    "\n",
    "### Vandalism\n",
    "* Interference with normal service without direct gain to attacker\n",
    "* Ex. Denial of service attack\n",
    "\n",
    "### Common attack\n",
    "* Eavesdropping : attackers taos into network\n",
    "* Masquerading : Attacker pretends to be someone else i,e Identity theft\n",
    "* Message tempering : Attacker modify message\n",
    "* Replay attack: Attacker replay old message\n",
    "* Denial of service : Bombard a port\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIA properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Service has to provide,\n",
    "    - Confidentiality : Protection against disclosure to unauthorized individuals, address leakage threat\n",
    "    - Integrity : Protection against unauthorized alteration or corruption. Address tampering threat\n",
    "    - Availability : service is always readable and writable. Address vandalism threat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Security policy indicates what, mechanism indicate how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "* Is user claiming to be really is?\n",
    "\n",
    "### Authorization\n",
    "* User is authenticated but not allowed to perform her requested operation.\n",
    "\n",
    "### Auditing\n",
    "* How someone manage to attack? Usually done by logging all operation continuously.\n",
    "\n",
    "### Cryptography:\n",
    "* Keys is sequence of bytes assigned to user, can be used to lock a message and only this key can be used to unlock a message. \n",
    "* Message + Key -> Encryption -> Encoded message\n",
    "* Encoded message + key -> Decryption -> original message.\n",
    "* Shared/Symmetric key:\n",
    "    - Same key is used to both encrypt and decrypt\n",
    "    - Shared key reveal too much info. A group of people has same key. To remove user from group we have to change key.\n",
    "* Public Private key/asymmetric:\n",
    "    - User has private key known to him, user has public key known to everyone.\n",
    "    - Message encrypted by user's private key is only be decrypted by user's public key. Message encrypted by user's public key only be decrypted by user's private key. Ex. RSA, PGP. Longer the key hard to break.\n",
    "    - If A want to send message to B, A will encrypt message using B's public key. Bob's private key will able to decrypt it.\n",
    "* Authentication\n",
    "    - 2 users verify each other\n",
    "    - Direct authentication: Directly between 2 parties\n",
    "    ![](images/direct_authentication.PNG)\n",
    "    - Indirect authentication : Uses a trusted 3rd party server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Digital signature\n",
    "    - Signature is encrypted by sender's private key and can be verified using public key of user\n",
    "* Digital certificate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Authorization\n",
    "    - Access control matrix: For every combination  of user, object say what access mode is allowed. Large and parse(most entries has no access)\n",
    "    - Access control list (ACL) : Per object list of allowed users and access allowed to each\n",
    "    - Capability list: Per user, list of file allowed to access and type of access allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data center Outage\n",
    "* Power outage\n",
    "* Over heating\n",
    "* Human error\n",
    "* Fire\n",
    "* DOS attacks\n",
    "* System operator deleted database and backup\n",
    "* Shutdown of correctly working system\n",
    "* Even after error, cascading error make even worst.\n",
    "    - In facebook cache server ask for configuration file and it was invalid. So per second so many request to config storage and it was overloaded. Which trigger cache server to time out and they send more request to get correct condig files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
